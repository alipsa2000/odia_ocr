{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Model\n",
    "import time \n",
    "import pickle\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Classes Detected = 47\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  \n",
      "No of images imported = 15040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GLOBAL VARIABLES\n",
    "path = \"data1/NITROHCS_V1.0/\"\n",
    "inputShape = (32, 32, 3)\n",
    "batchsizeVal = 64\n",
    "epochsVal = 50\n",
    "# Importing Classes\n",
    "myList = os.listdir(path)\n",
    "noofclasses = len(myList)\n",
    "print(\"No of Classes Detected =\", noofclasses)\n",
    "images = []\n",
    "classid = []\n",
    "# Importing Images\n",
    "for x in range(0, noofclasses):\n",
    "    picList = os.listdir(path + \"/\" + myList[x])\n",
    "    for y in picList:\n",
    "        curImg = cv2.imread(path + \"/\" + myList[x] + \"/\" + y)\n",
    "        curImg = cv2.resize(curImg, (inputShape[0], inputShape[1]))\n",
    "        images.append(curImg)\n",
    "        classid.append(x)\n",
    "    print(x, end=\" \")\n",
    "print(\" \")\n",
    "print(\"No of images imported =\", len(images))\n",
    "\n",
    "# Convert to numpy array\n",
    "images = np.array(images)\n",
    "classid = np.array(classid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the Data\n",
    "classid = classid.reshape(-1, 1)\n",
    "onehotencoder = OneHotEncoder()\n",
    "Y = onehotencoder.fit_transform(classid).toarray()\n",
    "\n",
    "images, Y = shuffle(images, Y, random_state=69)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, Y, test_size=0.2, random_state=69)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=69\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing\n",
    "# def preprocessing(img):\n",
    "#     img = img / 255\n",
    "#     # img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     # img = cv2.equalizeHist(img)\n",
    "#     return img\n",
    "\n",
    "# X_train = np.array(list(map(preprocessing, x_train)))\n",
    "# X_test = np.array(list(map(preprocessing, x_test)))\n",
    "# X_validation = np.array(list(map(preprocessing, x_validation)))\n",
    "# Reshape images\n",
    "X_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n",
    "X_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "X_validation = x_validation.reshape(\n",
    "    x_validation.shape[0], x_validation.shape[1], x_validation.shape[2], 3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Augmenting Images\n",
    "dataGen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=10,\n",
    ")\n",
    "dataGen.fit(x_train)\n",
    "class_weights = {}\n",
    "unique, counts = np.unique(classid, return_counts=True)\n",
    "total = np.sum(counts)\n",
    "for i in range(len(unique)):\n",
    "    class_weights[unique[i]] = total / (len(unique) * counts[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 47)                192559    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,008,495\n",
      "Trainable params: 4,653,615\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG16 model\n",
    "vgg = VGG16(input_shape=inputShape, weights='imagenet', include_top=False)\n",
    "# for layer in vgg.layers:\n",
    "#     layer.trainable = False\n",
    "for i, layer in enumerate(vgg.layers):\n",
    "    if i < len(vgg.layers) - 2:\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True\n",
    "\n",
    "X_train = preprocess_input(X_train) \n",
    "X_test = preprocess_input(X_test)\n",
    "x = Flatten()(vgg.output)\n",
    "# dense_layer1 = Dense(512, activation='relu')\n",
    "    #add another fully connected layers with batch norm and dropout\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "    \n",
    "    # #add another fully connected layers with batch norm and dropout\n",
    "    # x = Dense(4096, activation='relu')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(dropoutRate)(x)\n",
    "prediction = Dense(noofclasses, activation='softmax')(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "151/151 [==============================] - 128s 842ms/step - loss: 4.9152 - accuracy: 0.1368 - val_loss: 2.4880 - val_accuracy: 0.3398\n",
      "Epoch 2/70\n",
      "151/151 [==============================] - 118s 782ms/step - loss: 2.6606 - accuracy: 0.3071 - val_loss: 1.9834 - val_accuracy: 0.4479\n",
      "Epoch 3/70\n",
      "151/151 [==============================] - 113s 749ms/step - loss: 2.2314 - accuracy: 0.3854 - val_loss: 1.8063 - val_accuracy: 0.4923\n",
      "Epoch 4/70\n",
      "151/151 [==============================] - 109s 719ms/step - loss: 1.9274 - accuracy: 0.4554 - val_loss: 1.6785 - val_accuracy: 0.5193\n",
      "Epoch 5/70\n",
      "151/151 [==============================] - 117s 778ms/step - loss: 1.7498 - accuracy: 0.4977 - val_loss: 1.5353 - val_accuracy: 0.5746\n",
      "Epoch 6/70\n",
      "151/151 [==============================] - 606s 4s/step - loss: 1.5963 - accuracy: 0.5343 - val_loss: 1.7945 - val_accuracy: 0.5538\n",
      "Epoch 7/70\n",
      "151/151 [==============================] - 12677s 85s/step - loss: 1.5006 - accuracy: 0.5633 - val_loss: 1.5287 - val_accuracy: 0.5945\n",
      "Epoch 8/70\n",
      "151/151 [==============================] - 118s 780ms/step - loss: 1.3999 - accuracy: 0.5834 - val_loss: 1.2071 - val_accuracy: 0.6535\n",
      "Epoch 9/70\n",
      "151/151 [==============================] - 169s 1s/step - loss: 1.2789 - accuracy: 0.6145 - val_loss: 1.3190 - val_accuracy: 0.6365\n",
      "Epoch 10/70\n",
      "151/151 [==============================] - 198s 1s/step - loss: 1.2256 - accuracy: 0.6288 - val_loss: 1.3427 - val_accuracy: 0.6494\n",
      "Epoch 11/70\n",
      "151/151 [==============================] - 237s 2s/step - loss: 1.1843 - accuracy: 0.6335 - val_loss: 1.0591 - val_accuracy: 0.6897\n",
      "Epoch 12/70\n",
      "151/151 [==============================] - 234s 2s/step - loss: 1.1047 - accuracy: 0.6553 - val_loss: 1.0812 - val_accuracy: 0.6942\n",
      "Epoch 13/70\n",
      "151/151 [==============================] - 1565s 10s/step - loss: 1.0839 - accuracy: 0.6665 - val_loss: 1.2493 - val_accuracy: 0.6722\n",
      "Epoch 14/70\n",
      "151/151 [==============================] - 225s 1s/step - loss: 1.0398 - accuracy: 0.6753 - val_loss: 1.1316 - val_accuracy: 0.6905\n",
      "Epoch 15/70\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.9780 - accuracy: 0.6956 - val_loss: 1.3727 - val_accuracy: 0.6460\n",
      "Epoch 16/70\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.9718 - accuracy: 0.7001 - val_loss: 0.9447 - val_accuracy: 0.7241\n",
      "Epoch 17/70\n",
      "151/151 [==============================] - 5276s 35s/step - loss: 0.9278 - accuracy: 0.7092 - val_loss: 0.9160 - val_accuracy: 0.7470\n",
      "Epoch 18/70\n",
      "151/151 [==============================] - 184s 1s/step - loss: 0.8977 - accuracy: 0.7198 - val_loss: 0.9711 - val_accuracy: 0.7283\n",
      "Epoch 19/70\n",
      "151/151 [==============================] - 171s 1s/step - loss: 0.8986 - accuracy: 0.7188 - val_loss: 0.9011 - val_accuracy: 0.7279\n",
      "Epoch 20/70\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.8521 - accuracy: 0.7379 - val_loss: 0.9365 - val_accuracy: 0.7320\n",
      "Epoch 21/70\n",
      "151/151 [==============================] - 2840s 19s/step - loss: 0.8220 - accuracy: 0.7406 - val_loss: 0.8509 - val_accuracy: 0.7374\n",
      "Epoch 22/70\n",
      "151/151 [==============================] - 279s 2s/step - loss: 0.8033 - accuracy: 0.7454 - val_loss: 0.8889 - val_accuracy: 0.7457\n",
      "Epoch 23/70\n",
      "151/151 [==============================] - 394s 3s/step - loss: 0.7909 - accuracy: 0.7568 - val_loss: 0.8659 - val_accuracy: 0.7511\n",
      "Epoch 24/70\n",
      "151/151 [==============================] - 283s 2s/step - loss: 0.7684 - accuracy: 0.7579 - val_loss: 0.9613 - val_accuracy: 0.7349\n",
      "Epoch 25/70\n",
      "151/151 [==============================] - 209s 1s/step - loss: 0.7474 - accuracy: 0.7600 - val_loss: 0.9893 - val_accuracy: 0.7287\n",
      "Epoch 26/70\n",
      "151/151 [==============================] - 246s 2s/step - loss: 0.7534 - accuracy: 0.7646 - val_loss: 0.6998 - val_accuracy: 0.7865\n",
      "Epoch 27/70\n",
      "151/151 [==============================] - 235s 2s/step - loss: 0.7362 - accuracy: 0.7679 - val_loss: 0.7803 - val_accuracy: 0.7703\n",
      "Epoch 28/70\n",
      "151/151 [==============================] - 225s 1s/step - loss: 0.7168 - accuracy: 0.7752 - val_loss: 0.7236 - val_accuracy: 0.7752\n",
      "Epoch 29/70\n",
      "151/151 [==============================] - 233s 2s/step - loss: 0.6992 - accuracy: 0.7788 - val_loss: 1.0117 - val_accuracy: 0.7304\n",
      "Epoch 30/70\n",
      " 34/151 [=====>........................] - ETA: 2:27 - loss: 0.6842 - accuracy: 0.7794"
     ]
    }
   ],
   "source": [
    "\n",
    "adam = optimizers.Adam(learning_rate=1e-6)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=adam,\n",
    "    metrics=['accuracy']\n",
    "\n",
    ")\n",
    "# Saving the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"Resnet_100.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Early Stopping is a regularization method (To minimize overfitting)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "history = model.fit(dataGen.flow(X_train, y_train, batch_size=batchsizeVal),\n",
    "                    epochs=epochsVal,\n",
    "                    validation_data=(X_validation, y_validation),\n",
    "                    shuffle=True,\n",
    "                    class_weight=class_weights,\n",
    "                    verbose=1,callbacks=[tensorboard_callback,time_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss Score =', score[0])\n",
    "print('Test Accuracy =', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "pickle_out = open(\"model_trained_iitbbs_googlenet.p\", \"wb\")\n",
    "pickle.dump(model, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred >= 0.5)\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
